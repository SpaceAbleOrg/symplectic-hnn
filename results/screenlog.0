Which model (data set name) do you want to use ?spring-pe   ,pendulum
Which numerical method for training (default midpoint) ?forw-euler,s symp-euler,midpoint
Which step size h (default 0.1) ?0.8,0.4,0.2,0.1,0.05
joblib.externals.loky.process_executor._RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/spaceable/anaconda3/envs/main3.9/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py", line 431, in _process_worker
    r = call_item()
  File "/home/spaceable/anaconda3/envs/main3.9/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py", line 285, in __call__
    return self.fn(*self.args, **self.kwargs)
  File "/home/spaceable/anaconda3/envs/main3.9/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 595, in __call__
    return self.func(*args, **kwargs)
  File "/home/spaceable/anaconda3/envs/main3.9/lib/python3.9/site-packages/joblib/parallel.py", line 262, in __call__
    return [func(*args, **kwargs)
  File "/home/spaceable/anaconda3/envs/main3.9/lib/python3.9/site-packages/joblib/parallel.py", line 262, in <listcomp>
    return [func(*args, **kwargs)
  File "/home/spaceable/deploy/train.py", line 139, in train_main
    model, loss_log = train(model, data, args)
  File "/home/spaceable/deploy/train.py", line 71, in train
    loss_fct = OneStepLoss(args)  # Choosing the actual loss_type is hidden in this constructor
  File "/home/spaceable/deploy/model/loss.py", line 144, in __init__
    self.scheme = choose_scheme(self.args.loss_type)(self.args)
  File "/home/spaceable/deploy/model/loss.py", line 91, in choose_scheme
    return choose_helper(schemes, name, choose_what="Integration scheme")
  File "/home/spaceable/deploy/utils.py", line 69, in choose_helper
    raise ValueError(f"{choose_what} not recognized: {name}. Possibilities are: " + ", ".join(dict.keys()))
ValueError: Integration scheme not recognized: forw-euler. Possibilities are: euler-forw, euler-symp, midpoint
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/spaceable/deploy/parallelize.py", line 45, in <module>
    train_parallel(load_args(custom_prod=prompt()))
  File "/home/spaceable/deploy/parallelize.py", line 41, in train_parallel
    Parallel(n_jobs=-1, verbose=joblib_verbose)(delayed(train_main)(args) for args in arg_iterable)
  File "/home/spaceable/anaconda3/envs/main3.9/lib/python3.9/site-packages/joblib/parallel.py", line 1054, in __call__
    self.retrieve()
  File "/home/spaceable/anaconda3/envs/main3.9/lib/python3.9/site-packages/joblib/parallel.py", line 933, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/spaceable/anaconda3/envs/main3.9/lib/python3.9/site-packages/joblib/_parallel_backends.py", line 542, in wrap_future_result
    return future.result(timeout=timeout)
  File "/home/spaceable/anaconda3/envs/main3.9/lib/python3.9/concurrent/futures/_base.py", line 440, in result
    return self.__get_result()
  File "/home/spaceable/anaconda3/envs/main3.9/lib/python3.9/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
ValueError: Integration scheme not recognized: forw-euler. Possibilities are: euler-forw, euler-symp, midpoint
Which model (data set name) do you want to use ?spring,pendulum
Which numerical method for training (default midpoint) ?euler-symp,euler-forw,midpoii nt
Which step size h (default 0.1) ?0.8,0.4,0.2,0.1,0.05
^[[B^[[B^[[B^[[A^[[A^[[A^[[AFinal train loss 2.9864e-02 +/- 1.2891e-03
Final test loss 3.1266e-02 +/- 2.8119e-03
Final train loss 6.5349e-07 +/- 4.3611e-08
Final test loss 7.4877e-07 +/- 1.1605e-07
Final train loss 4.6835e-07 +/- 3.6091e-08
Final test loss 5.6691e-07 +/- 1.0069e-07
Final train loss 4.5265e-07 +/- 3.6299e-08
Final test loss 5.5607e-07 +/- 9.8495e-08
Final train loss 2.2692e-06 +/- 1.2279e-07
Final test loss 2.3236e-06 +/- 2.3707e-07
Final train loss 4.4924e-07 +/- 3.6884e-08
Final test loss 5.4835e-07 +/- 9.7251e-08
Final train loss 8.4036e-03 +/- 3.2653e-04
Final test loss 8.2916e-03 +/- 6.5515e-04
Final train loss 2.1462e-03 +/- 8.4186e-05
Final test loss 2.1071e-03 +/- 1.6809e-04
Final train loss 1.3540e-04 +/- 5.3024e-06
Final test loss 1.3272e-04 +/- 1.0497e-05
Final train loss 5.4022e-04 +/- 2.1101e-05
Final test loss 5.2948e-04 +/- 4.1917e-05
Final train loss 5.0680e-07 +/- 3.8320e-08
Final test loss 5.4905e-07 +/- 9.9979e-08
Final train loss 3.9059e-07 +/- 2.8418e-08
Final test loss 4.4653e-07 +/- 7.6398e-08
Final train loss 3.9438e-07 +/- 2.7732e-08
Final test loss 4.5745e-07 +/- 7.4656e-08
Final train loss 3.9778e-07 +/- 2.8339e-08
Final test loss 4.6620e-07 +/- 7.6505e-08
Final train loss 3.8628e-07 +/- 2.7518e-08
Final test loss 4.5612e-07 +/- 7.5446e-08
Final train loss 3.0554e-05 +/- 5.2911e-06
Final test loss 3.0807e-05 +/- 6.6965e-06
Final train loss 3.0422e-05 +/- 4.6284e-06
Final test loss 4.6482e-05 +/- 2.1401e-05
Final train loss 3.3163e-05 +/- 4.7673e-06
Final test loss 4.1410e-05 +/- 1.7561e-05
Final train loss 3.3022e-05 +/- 4.8455e-06
Final test loss 3.5867e-05 +/- 1.1840e-05
Final train loss 7.2556e-02 +/- 2.9257e-03
Final test loss 8.6786e-02 +/- 7.3944e-03
Final train loss 2.1471e-02 +/- 8.9677e-04
Final test loss 2.4819e-02 +/- 2.1052e-03
Final train loss 3.2634e-05 +/- 4.5070e-06
Final test loss 3.7467e-05 +/- 1.1764e-05
Final train loss 5.6227e-03 +/- 2.3729e-04
Final test loss 6.4335e-03 +/- 5.5024e-04
Final train loss 1.4450e-03 +/- 6.0519e-05
Final test loss 1.6531e-03 +/- 1.4003e-04
Final train loss 3.8905e-04 +/- 1.5869e-05
Final test loss 4.4038e-04 +/- 3.6073e-05
Final train loss 3.2457e-05 +/- 4.0912e-06
Final test loss 3.5766e-05 +/- 6.2571e-06
Final train loss 3.3271e-05 +/- 5.1775e-06
Final test loss 4.4833e-05 +/- 2.1152e-05
Final train loss 3.4787e-05 +/- 5.1037e-06
Final test loss 4.5840e-05 +/- 1.9645e-05
Final train loss 3.3314e-05 +/- 4.6836e-06
Final test loss 3.7088e-05 +/- 1.2061e-05
Final train loss 3.1642e-05 +/- 4.3208e-06
Final test loss 3.3251e-05 +/- 7.7749e-06
